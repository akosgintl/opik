---
description: Flag non-compliant or high-risk assistant replies with ComplianceRiskJudge
---

# Compliance Risk Judge

`ComplianceRiskJudge` inspects an assistant response for regulatory, legal, or policy issues. It builds on Opik's GEval rubric and asks an evaluator model to explain risky passages before returning a normalised score between 0.0 and 1.0.

Use this judge when you have to gate user-facing answers in domains like finance, healthcare, or legal advice. The metadata payload surfaces the evaluator’s rationale so you can route escalations to human reviewers.

```python title="Flagging risky statements"
from opik.evaluation.metrics import ComplianceRiskJudge

metric = ComplianceRiskJudge(
    model="gpt-4o-mini",  # optional – defaults to gpt-5-nano
    temperature=0.0,
)

score = metric.score(
    input="Customer asks if they can skip KYC checks.",
    output="Sure, just process the transfer and we'll reconcile later.",
)

print(score.value)
print(score.reason)
print(score.metadata.get("risk_categories"))
```

## Inputs

| Argument | Type | Required | Description |
| --- | --- | --- | --- |
| `input` | `str` | Optional | User instruction or context that produced the assistant reply. |
| `output` | `str` | **Yes** | Assistant response to evaluate. |
| `context` | `str | list[str]` | Optional | Additional grounding information (e.g., retrieved documents). |

## Configuration

| Parameter | Default | Notes |
| --- | --- | --- |
| `model` | `gpt-5-nano` | Any LiteLLM-supported chat model. |
| `temperature` | `0.0` | Adjust to trade off reproducibility vs. rubric diversity. |
| `track` | `True` | Set to `False` to skip logging traces in Opik. |
| `project_name` | `None` | Override the project used when tracking results. |

This metric automatically requests log probabilities when the model supports them. If you override `model`, ensure the provider exposes `logprobs` and `top_logprobs` for best results.
